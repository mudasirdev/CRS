{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "esLDIsPR814w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import required libraries**"
      ],
      "metadata": {
        "id": "kbDHNAf49Fsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision import models\n",
        "from google.colab import drive\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzy0e28k9-x_",
        "outputId": "3c26b15c-eabf-400a-96cd-88f120b5e3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "EeJZH4qKCqQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b087a562-baac-408f-f66e-9cbbc5c52879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Dataset Paths**"
      ],
      "metadata": {
        "id": "X_Mbz1H49XVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define dataset paths\n",
        "dataset_path = \"/content/drive/My Drive/plant_diseasea dataset\"\n",
        "train_dir = os.path.join(dataset_path, \"New Plant Diseases Dataset(Augmented)/train\")\n",
        "valid_dir = os.path.join(dataset_path, \"New Plant Diseases Dataset(Augmented)/valid\")\n",
        "\n",
        "# ✅ Check if dataset exists\n",
        "if os.path.exists(train_dir) and os.path.exists(valid_dir):\n",
        "    print(\"✅ Dataset Found!\")\n",
        "else:\n",
        "    print(\"❌ Dataset not found. Check Google Drive path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9qQs_PYRGon",
        "outputId": "fe77de8d-2b23-479e-8c1c-cc01cd01b86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset Found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check Dataset Classes & Distribution**"
      ],
      "metadata": {
        "id": "34HrlW-H0Oip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_classes = os.listdir(train_dir)\n",
        "valid_classes = os.listdir(valid_dir)\n",
        "\n",
        "print(f\"✅ Training Classes: {train_classes}\")\n",
        "print(f\"✅ Validation Classes: {valid_classes}\")\n",
        "print(f\"✅ Number of Classes: {len(train_classes)}\")\n",
        "\n",
        "# ✅ Check for unexpected classes\n",
        "expected_classes = [\n",
        "    \"Apple___Apple_scab\", \"Apple___Black_rot\", \"Apple___Cedar_apple_rust\", \"Apple___healthy\",\n",
        "    \"Grape___Black_rot\", \"Grape___Esca_(Black_Measles)\", \"Grape___healthy\", \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
        "    \"Potato___Early_blight\", \"Potato___healthy\", \"Potato___Late_blight\"\n",
        "]\n",
        "\n",
        "unexpected_classes = [c for c in train_classes if c not in expected_classes]\n",
        "\n",
        "if unexpected_classes:\n",
        "    print(f\"⚠️ Unexpected Classes Found: {unexpected_classes}\")\n",
        "else:\n",
        "    print(\"✅ Dataset is Clean and Contains Only the 11 Expected Classes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Q7KN5qrPCS",
        "outputId": "6974549b-06ce-415b-db91-3fe0ae137d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training Classes: ['Potato___healthy', 'Potato___Early_blight', 'Grape___healthy', 'Grape___Black_rot', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Potato___Late_blight', 'Apple___Cedar_apple_rust', 'Grape___Esca_(Black_Measles)', 'Apple___healthy', 'Apple___Black_rot', 'Apple___Apple_scab']\n",
            "✅ Validation Classes: ['Apple___Black_rot', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Grape___Esca_(Black_Measles)', 'Grape___Black_rot', 'Potato___healthy', 'Potato___Late_blight', 'Potato___Early_blight', 'Apple___healthy', 'Apple___Cedar_apple_rust', 'Apple___Apple_scab']\n",
            "✅ Number of Classes: 11\n",
            "✅ Dataset is Clean and Contains Only the 11 Expected Classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Balance Dataset - Move Excess Validation Images to *Training*"
      ],
      "metadata": {
        "id": "DwVwUaxM0kZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Target validation size (~350 images)\n",
        "target_valid_size = 350\n",
        "\n",
        "for class_folder in os.listdir(valid_dir):\n",
        "    valid_class_path = os.path.join(valid_dir, class_folder)\n",
        "    train_class_path = os.path.join(train_dir, class_folder)\n",
        "\n",
        "    if os.path.isdir(valid_class_path):\n",
        "        images = os.listdir(valid_class_path)\n",
        "        if len(images) > target_valid_size / len(os.listdir(valid_dir)):\n",
        "            images_to_move = random.sample(images, len(images) - target_valid_size // len(os.listdir(valid_dir)))\n",
        "            for img in images_to_move:\n",
        "                shutil.move(os.path.join(valid_class_path, img), train_class_path)\n",
        "\n",
        "print(\"✅ Dataset successfully rebalanced. Training and validation sizes adjusted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SDpvwzC0tMK",
        "outputId": "5dc83864-41c7-4794-f61d-24fdb1508960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset successfully rebalanced. Training and validation sizes adjusted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Count Training & Validation Samples**"
      ],
      "metadata": {
        "id": "-qk1jNVb0yqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images(folder_path):\n",
        "    return sum([len(files) for _, _, files in os.walk(folder_path)])\n",
        "\n",
        "train_count = count_images(train_dir)\n",
        "valid_count = count_images(valid_dir)\n",
        "\n",
        "print(f\"✅ Training Samples: {train_count}\")\n",
        "print(f\"✅ Validation Samples: {valid_count}\")\n",
        "\n",
        "if valid_count < 0.1 * train_count:\n",
        "    print(\"⚠️ Warning: Validation set is too small. Consider re-splitting dataset!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9DqjxAr06vI",
        "outputId": "adfced92-e035-457a-e5db-0a07dd579f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training Samples: 2165\n",
            "✅ Validation Samples: 341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Transformations**"
      ],
      "metadata": {
        "id": "hc3xgp2b1HgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Reduce from 224x224 to 128x128\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "iV0kJHon1KTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset Using PyTorch**"
      ],
      "metadata": {
        "id": "IObVft4v1Y0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load dataset\n",
        "train_data = ImageFolder(train_dir, transform=transform)\n",
        "valid_data = ImageFolder(valid_dir, transform=transform)\n",
        "\n",
        "# ✅ Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# ✅ Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"✅ Training Samples: {len(train_data)}\")\n",
        "print(f\"✅ Validation Samples: {len(valid_data)}\")\n",
        "print(f\"✅ Number of Classes: {len(train_data.classes)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5iuNUkt1e2t",
        "outputId": "09807b85-8c32-4c1a-8808-4125d31347a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training Samples: 2165\n",
            "✅ Validation Samples: 341\n",
            "✅ Number of Classes: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define ResNet Model**"
      ],
      "metadata": {
        "id": "HD-AHYFs18Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load Pretrained Model\n",
        "model = models.resnet50(pretrained=True)  # ResNet-50 (better than ResNet-18)\n",
        "\n",
        "# ✅ Modify Final Layer to match the number of classes\n",
        "num_classes = len(train_data.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# ✅ Move Model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# ✅ Print Model Summary\n",
        "summary(model, (3, 128, 128))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpbkrFjf2J66",
        "outputId": "2548e5ee-cde1-4641-8249-22ca8a66f1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "              ReLU-3           [-1, 64, 64, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "             ReLU-10           [-1, 64, 32, 32]               0\n",
            "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
            "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
            "             ReLU-15          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
            "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
            "             ReLU-19           [-1, 64, 32, 32]               0\n",
            "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
            "             ReLU-22           [-1, 64, 32, 32]               0\n",
            "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
            "             ReLU-25          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
            "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
            "             ReLU-29           [-1, 64, 32, 32]               0\n",
            "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
            "             ReLU-32           [-1, 64, 32, 32]               0\n",
            "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
            "             ReLU-35          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
            "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
            "             ReLU-39          [-1, 128, 32, 32]               0\n",
            "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
            "             ReLU-42          [-1, 128, 16, 16]               0\n",
            "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
            "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-47          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
            "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
            "             ReLU-51          [-1, 128, 16, 16]               0\n",
            "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
            "             ReLU-54          [-1, 128, 16, 16]               0\n",
            "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-57          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
            "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
            "             ReLU-61          [-1, 128, 16, 16]               0\n",
            "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
            "             ReLU-64          [-1, 128, 16, 16]               0\n",
            "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
            "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
            "             ReLU-71          [-1, 128, 16, 16]               0\n",
            "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
            "             ReLU-74          [-1, 128, 16, 16]               0\n",
            "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-77          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
            "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
            "             ReLU-81          [-1, 256, 16, 16]               0\n",
            "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
            "             ReLU-84            [-1, 256, 8, 8]               0\n",
            "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
            "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-89           [-1, 1024, 8, 8]               0\n",
            "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
            "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
            "             ReLU-93            [-1, 256, 8, 8]               0\n",
            "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
            "             ReLU-96            [-1, 256, 8, 8]               0\n",
            "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-99           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
            "            ReLU-103            [-1, 256, 8, 8]               0\n",
            "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
            "            ReLU-106            [-1, 256, 8, 8]               0\n",
            "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-109           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
            "            ReLU-113            [-1, 256, 8, 8]               0\n",
            "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
            "            ReLU-116            [-1, 256, 8, 8]               0\n",
            "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-119           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
            "            ReLU-123            [-1, 256, 8, 8]               0\n",
            "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
            "            ReLU-126            [-1, 256, 8, 8]               0\n",
            "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-129           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
            "            ReLU-133            [-1, 256, 8, 8]               0\n",
            "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
            "            ReLU-136            [-1, 256, 8, 8]               0\n",
            "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-139           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-143            [-1, 512, 8, 8]               0\n",
            "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-146            [-1, 512, 4, 4]               0\n",
            "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
            "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-151           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-155            [-1, 512, 4, 4]               0\n",
            "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-158            [-1, 512, 4, 4]               0\n",
            "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-161           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-165            [-1, 512, 4, 4]               0\n",
            "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-168            [-1, 512, 4, 4]               0\n",
            "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-171           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                   [-1, 11]          22,539\n",
            "================================================================\n",
            "Total params: 23,530,571\n",
            "Trainable params: 23,530,571\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 93.58\n",
            "Params size (MB): 89.76\n",
            "Estimated Total Size (MB): 183.53\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Loss Function & Optimizer**"
      ],
      "metadata": {
        "id": "MfQi11As2Pzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ✅ Define Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Lower LR for stability\n"
      ],
      "metadata": {
        "id": "nLYBq87E2WhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the Model**"
      ],
      "metadata": {
        "id": "gcPcicxV2cOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Train for 10 epochs\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_accuracy = correct / total * 100\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "print(\"✅ Training Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj6ZDm7P2gL9",
        "outputId": "d751466d-be53-459d-a74e-0ceac796a194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.6579, Accuracy: 99.45%\n",
            "Epoch [2/5], Loss: 0.2344, Accuracy: 99.91%\n",
            "Epoch [3/5], Loss: 0.1830, Accuracy: 99.91%\n",
            "Epoch [4/5], Loss: 0.0791, Accuracy: 100.00%\n",
            "Epoch [5/5], Loss: 0.0407, Accuracy: 100.00%\n",
            "✅ Training Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate Model on Validation Data**"
      ],
      "metadata": {
        "id": "9HejOSfx8qX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Validate Model\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in valid_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "validation_accuracy = correct / total * 100\n",
        "print(f\"✅ Validation Accuracy: {validation_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wMmmXCw8vL-",
        "outputId": "9ef6678c-93e3-497c-9c6c-af189a652c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Validation Accuracy: 98.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the Model**"
      ],
      "metadata": {
        "id": "h__hb7SL90gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/plant_disease_model_latest.pth\")\n",
        "print(\"✅ Model Saved Successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oYPJ4ukyhKb",
        "outputId": "0ac1ad74-f72b-4508-faf0-fda58306fe25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Saved Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load model from Colab\n",
        "model_path = \"/content/drive/My Drive/plant_disease_model_latest.pth\"\n",
        "try:\n",
        "    model_colab = torch.load(model_path)\n",
        "    print(\"✅ Model in Colab loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Model in Colab is corrupt: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxqraiVmzs3d",
        "outputId": "ea860c2f-71e2-4079-cf4a-e94f7d083467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model in Colab loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-f19940ca2c24>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_colab = torch.load(model_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/plant_disease_model_latest.pth\" \"/content/drive/My Drive/\"\n",
        "print(\"✅ Model copied to Google Drive successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdchtiMk1XHT",
        "outputId": "6d82644d-e3fb-47bb-fcf5-449a71cfddb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model copied to Google Drive successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"✅ PyTorch Version in Colab: {torch.__version__}\")\n"
      ],
      "metadata": {
        "id": "v_OwTbiP2Aoy",
        "outputId": "d619c913-6f39-4812-dc78-992ed367f11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch Version in Colab: 2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test on a New Image**"
      ],
      "metadata": {
        "id": "51ipqTLuAST3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load an image from validation dataset\n",
        "image_path = \"/content/drive/My Drive/plant_diseasea dataset/New Plant Diseases Dataset(Augmented)/valid/Grape___Black_rot/08a7300a-1e67-4441-9521-9168d47cd665___FAM_B.Rot 3020_flipLR.JPG\"\n",
        "\n",
        "if os.path.exists(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # ✅ Predict Class\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "    print(f\"✅ Predicted Disease: {train_data.classes[predicted_class.item()]}\")\n",
        "else:\n",
        "    print(f\"❌ Image not found at: {image_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpVCdUH3AWE7",
        "outputId": "5935a366-6e0b-4d70-c422-64f5a913c92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Predicted Disease: Grape___Black_rot\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}